{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOY+3ZkAk3SbryXZZ8Q5tAC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ibraheem101/Data-Science-learning/blob/main/nltk_tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "p5M-mAiD9Mvh"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import nltk\n",
        "import nltk.corpus"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BGzDIx1sFNIT",
        "outputId": "02a3aaae-fb63-4039-e763-c0e0f331f8a2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('brown')\n",
        "nltk.download('gutenberg')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NIeSAWEy_DWM",
        "outputId": "3aa922b0-30ed-4ab9-fa4f-44048d67f6e8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Package brown is already up-to-date!\n",
            "[nltk_data] Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]   Package gutenberg is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import brown, gutenberg"
      ],
      "metadata": {
        "id": "eSNPmwD39aOs"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "brown.words()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kPQZzKdB-mDd",
        "outputId": "69d1e393-3067-4e25-f240-98d4ebf616f7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', ...]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.corpus.gutenberg.fileids()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1EFoyVGxAY61",
        "outputId": "fc683285-3953-4bbc-907d-6ffa65f15250"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['austen-emma.txt',\n",
              " 'austen-persuasion.txt',\n",
              " 'austen-sense.txt',\n",
              " 'bible-kjv.txt',\n",
              " 'blake-poems.txt',\n",
              " 'bryant-stories.txt',\n",
              " 'burgess-busterbrown.txt',\n",
              " 'carroll-alice.txt',\n",
              " 'chesterton-ball.txt',\n",
              " 'chesterton-brown.txt',\n",
              " 'chesterton-thursday.txt',\n",
              " 'edgeworth-parents.txt',\n",
              " 'melville-moby_dick.txt',\n",
              " 'milton-paradise.txt',\n",
              " 'shakespeare-caesar.txt',\n",
              " 'shakespeare-hamlet.txt',\n",
              " 'shakespeare-macbeth.txt',\n",
              " 'whitman-leaves.txt']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hamlet = nltk.corpus.gutenberg.words('shakespeare-hamlet.txt')\n",
        "hamlet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BScCNEdMA6ni",
        "outputId": "dca7c2b5-aebe-4917-ec45-b723761c473c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['[', 'The', 'Tragedie', 'of', 'Hamlet', 'by', ...]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for word in hamlet[:500]:\n",
        "    print(word, sep = ' ', end = ' ')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ttX21KKcBZxo",
        "outputId": "3085ea14-2dc1-4564-f5d4-db450af8325e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ The Tragedie of Hamlet by William Shakespeare 1599 ] Actus Primus . Scoena Prima . Enter Barnardo and Francisco two Centinels . Barnardo . Who ' s there ? Fran . Nay answer me : Stand & vnfold your selfe Bar . Long liue the King Fran . Barnardo ? Bar . He Fran . You come most carefully vpon your houre Bar . ' Tis now strook twelue , get thee to bed Francisco Fran . For this releefe much thankes : ' Tis bitter cold , And I am sicke at heart Barn . Haue you had quiet Guard ? Fran . Not a Mouse stirring Barn . Well , goodnight . If you do meet Horatio and Marcellus , the Riuals of my Watch , bid them make hast . Enter Horatio and Marcellus . Fran . I thinke I heare them . Stand : who ' s there ? Hor . Friends to this ground Mar . And Leige - men to the Dane Fran . Giue you good night Mar . O farwel honest Soldier , who hath relieu ' d you ? Fra . Barnardo ha ' s my place : giue you goodnight . Exit Fran . Mar . Holla Barnardo Bar . Say , what is Horatio there ? Hor . A peece of him Bar . Welcome Horatio , welcome good Marcellus Mar . What , ha ' s this thing appear ' d againe to night Bar . I haue seene nothing Mar . Horatio saies , ' tis but our Fantasie , And will not let beleefe take hold of him Touching this dreaded sight , twice seene of vs , Therefore I haue intreated him along With vs , to watch the minutes of this Night , That if againe this Apparition come , He may approue our eyes , and speake to it Hor . Tush , tush , ' twill not appeare Bar . Sit downe a - while , And let vs once againe assaile your eares , That are so fortified against our Story , What we two Nights haue seene Hor . Well , sit we downe , And let vs heare Barnardo speake of this Barn . Last night of all , When yond same Starre that ' s Westward from the Pole Had made his course t ' illume that part of Heauen Where now it burnes , Marcellus and my selfe , The Bell then beating one Mar . Peace , breake thee of : Enter the Ghost . Looke where it comes againe Barn . In the same figure , like the King that ' s dead Mar . Thou art a Scholler ; speake to it Horatio Barn . Lookes it not like the King ? Marke it Horatio Hora . Most like : It harrowes me with fear & wonder Barn . It would be spoke too Mar . Question it Horatio Hor . What art "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "NLP = 'Natural Language Processing (NLP) is a field of artificial intelligence and computational linguistics that focuses on the interaction between computers and human language. It involves developing algorithms and models to enable computers to understand, interpret, and generate natural language. The history of NLP dates back to the 1950s when researchers started exploring machine translation and automatic language processing. The early years of NLP were primarily focused on rule-based systems, where linguistic rules and patterns were used to process and understand text. Today, NLP continues to evolve rapidly, driven by advancements in deep learning, the availability of vast amounts of textual data, and the exploration of novel techniques such as transfer learning and reinforcement learning. The field is focused on addressing challenges such as understanding context, handling ambiguity, and enabling machines to generate human-like text, opening up exciting possibilities for human-computer interaction and language understanding.'"
      ],
      "metadata": {
        "id": "AqCuGqCtBy-4"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(NLP)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y95TXZZJEQyM",
        "outputId": "f6f1f0fb-5015-4034-9080-445972e25d68"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "str"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Word tokenization"
      ],
      "metadata": {
        "id": "rFlyLMLWKRBy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize"
      ],
      "metadata": {
        "id": "vlWDt8-cERuY"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp_tokens = word_tokenize(NLP)\n",
        "nlp_tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NcIIrfi3ElM_",
        "outputId": "c6a023b3-d1fa-48ed-fff8-e798608add24"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Natural',\n",
              " 'Language',\n",
              " 'Processing',\n",
              " '(',\n",
              " 'NLP',\n",
              " ')',\n",
              " 'is',\n",
              " 'a',\n",
              " 'field',\n",
              " 'of',\n",
              " 'artificial',\n",
              " 'intelligence',\n",
              " 'and',\n",
              " 'computational',\n",
              " 'linguistics',\n",
              " 'that',\n",
              " 'focuses',\n",
              " 'on',\n",
              " 'the',\n",
              " 'interaction',\n",
              " 'between',\n",
              " 'computers',\n",
              " 'and',\n",
              " 'human',\n",
              " 'language',\n",
              " '.',\n",
              " 'It',\n",
              " 'involves',\n",
              " 'developing',\n",
              " 'algorithms',\n",
              " 'and',\n",
              " 'models',\n",
              " 'to',\n",
              " 'enable',\n",
              " 'computers',\n",
              " 'to',\n",
              " 'understand',\n",
              " ',',\n",
              " 'interpret',\n",
              " ',',\n",
              " 'and',\n",
              " 'generate',\n",
              " 'natural',\n",
              " 'language',\n",
              " '.',\n",
              " 'The',\n",
              " 'history',\n",
              " 'of',\n",
              " 'NLP',\n",
              " 'dates',\n",
              " 'back',\n",
              " 'to',\n",
              " 'the',\n",
              " '1950s',\n",
              " 'when',\n",
              " 'researchers',\n",
              " 'started',\n",
              " 'exploring',\n",
              " 'machine',\n",
              " 'translation',\n",
              " 'and',\n",
              " 'automatic',\n",
              " 'language',\n",
              " 'processing',\n",
              " '.',\n",
              " 'The',\n",
              " 'early',\n",
              " 'years',\n",
              " 'of',\n",
              " 'NLP',\n",
              " 'were',\n",
              " 'primarily',\n",
              " 'focused',\n",
              " 'on',\n",
              " 'rule-based',\n",
              " 'systems',\n",
              " ',',\n",
              " 'where',\n",
              " 'linguistic',\n",
              " 'rules',\n",
              " 'and',\n",
              " 'patterns',\n",
              " 'were',\n",
              " 'used',\n",
              " 'to',\n",
              " 'process',\n",
              " 'and',\n",
              " 'understand',\n",
              " 'text',\n",
              " '.',\n",
              " 'Today',\n",
              " ',',\n",
              " 'NLP',\n",
              " 'continues',\n",
              " 'to',\n",
              " 'evolve',\n",
              " 'rapidly',\n",
              " ',',\n",
              " 'driven',\n",
              " 'by',\n",
              " 'advancements',\n",
              " 'in',\n",
              " 'deep',\n",
              " 'learning',\n",
              " ',',\n",
              " 'the',\n",
              " 'availability',\n",
              " 'of',\n",
              " 'vast',\n",
              " 'amounts',\n",
              " 'of',\n",
              " 'textual',\n",
              " 'data',\n",
              " ',',\n",
              " 'and',\n",
              " 'the',\n",
              " 'exploration',\n",
              " 'of',\n",
              " 'novel',\n",
              " 'techniques',\n",
              " 'such',\n",
              " 'as',\n",
              " 'transfer',\n",
              " 'learning',\n",
              " 'and',\n",
              " 'reinforcement',\n",
              " 'learning',\n",
              " '.',\n",
              " 'The',\n",
              " 'field',\n",
              " 'is',\n",
              " 'focused',\n",
              " 'on',\n",
              " 'addressing',\n",
              " 'challenges',\n",
              " 'such',\n",
              " 'as',\n",
              " 'understanding',\n",
              " 'context',\n",
              " ',',\n",
              " 'handling',\n",
              " 'ambiguity',\n",
              " ',',\n",
              " 'and',\n",
              " 'enabling',\n",
              " 'machines',\n",
              " 'to',\n",
              " 'generate',\n",
              " 'human-like',\n",
              " 'text',\n",
              " ',',\n",
              " 'opening',\n",
              " 'up',\n",
              " 'exciting',\n",
              " 'possibilities',\n",
              " 'for',\n",
              " 'human-computer',\n",
              " 'interaction',\n",
              " 'and',\n",
              " 'language',\n",
              " 'understanding',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(nlp_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8d7QHuVuEv1C",
        "outputId": "b88ab430-14b5-4cd9-b703-ea8c65d86788"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "162"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.probability import FreqDist\n",
        "fdist = FreqDist()"
      ],
      "metadata": {
        "id": "MGoU1H3cGbYF"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for word in nlp_tokens:\n",
        "    fdist[word.lower()] += 1\n",
        "fdist"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KFdQVH6iHA3h",
        "outputId": "7aed8038-1404-4246-a504-99c3c134a3be"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FreqDist({'and': 11, ',': 10, 'the': 7, 'of': 6, '.': 6, 'to': 6, 'language': 5, 'nlp': 4, 'on': 3, 'learning': 3, ...})"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fdist.most_common(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d5smR4W9HDa2",
        "outputId": "5a8967f9-7f27-44ac-af8b-9188d1e1a8d8"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('and', 11), (',', 10), ('the', 7), ('of', 6), ('.', 6)]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fdist.items()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b63IG-0eHg5L",
        "outputId": "14e2fad4-0e5d-4a55-9deb-cbad7d8ad822"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_items([('natural', 2), ('language', 5), ('processing', 2), ('(', 1), ('nlp', 4), (')', 1), ('is', 2), ('a', 1), ('field', 2), ('of', 6), ('artificial', 1), ('intelligence', 1), ('and', 11), ('computational', 1), ('linguistics', 1), ('that', 1), ('focuses', 1), ('on', 3), ('the', 7), ('interaction', 2), ('between', 1), ('computers', 2), ('human', 1), ('.', 6), ('it', 1), ('involves', 1), ('developing', 1), ('algorithms', 1), ('models', 1), ('to', 6), ('enable', 1), ('understand', 2), (',', 10), ('interpret', 1), ('generate', 2), ('history', 1), ('dates', 1), ('back', 1), ('1950s', 1), ('when', 1), ('researchers', 1), ('started', 1), ('exploring', 1), ('machine', 1), ('translation', 1), ('automatic', 1), ('early', 1), ('years', 1), ('were', 2), ('primarily', 1), ('focused', 2), ('rule-based', 1), ('systems', 1), ('where', 1), ('linguistic', 1), ('rules', 1), ('patterns', 1), ('used', 1), ('process', 1), ('text', 2), ('today', 1), ('continues', 1), ('evolve', 1), ('rapidly', 1), ('driven', 1), ('by', 1), ('advancements', 1), ('in', 1), ('deep', 1), ('learning', 3), ('availability', 1), ('vast', 1), ('amounts', 1), ('textual', 1), ('data', 1), ('exploration', 1), ('novel', 1), ('techniques', 1), ('such', 2), ('as', 2), ('transfer', 1), ('reinforcement', 1), ('addressing', 1), ('challenges', 1), ('understanding', 2), ('context', 1), ('handling', 1), ('ambiguity', 1), ('enabling', 1), ('machines', 1), ('human-like', 1), ('opening', 1), ('up', 1), ('exciting', 1), ('possibilities', 1), ('for', 1), ('human-computer', 1)])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(NLP)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yyq0gOXiKaza",
        "outputId": "7b7f4a77-a7e6-47be-98c6-9a74cb86ce15"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1039"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Blank tokenization"
      ],
      "metadata": {
        "id": "H_UmnmZPKU4b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import blankline_tokenize"
      ],
      "metadata": {
        "id": "B5teFOdhHl8Z"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp_blank_tokens = blankline_tokenize(NLP)\n",
        "nlp_blank_tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Et4Nk-XYKu9u",
        "outputId": "7df64d34-7a4f-40ea-cf44-fd27bb8cae82"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Natural Language Processing (NLP) is a field of artificial intelligence and computational linguistics that focuses on the interaction between computers and human language. It involves developing algorithms and models to enable computers to understand, interpret, and generate natural language. The history of NLP dates back to the 1950s when researchers started exploring machine translation and automatic language processing. The early years of NLP were primarily focused on rule-based systems, where linguistic rules and patterns were used to process and understand text. Today, NLP continues to evolve rapidly, driven by advancements in deep learning, the availability of vast amounts of textual data, and the exploration of novel techniques such as transfer learning and reinforcement learning. The field is focused on addressing challenges such as understanding context, handling ambiguity, and enabling machines to generate human-like text, opening up exciting possibilities for human-computer interaction and language understanding.']"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(nlp_blank_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wDzYZq4DK5zI",
        "outputId": "6c5055c8-1c44-4f7f-f86b-18ece3602c46"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Bigrams, Trigrams and N-grams"
      ],
      "metadata": {
        "id": "endwg8deMT8t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.util import bigrams, trigrams, ngrams"
      ],
      "metadata": {
        "id": "mBJhARw5LAxA"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp_bigrams = list(nltk.bigrams(nlp_tokens))\n",
        "nlp_bigrams"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "it1sElHZNWOT",
        "outputId": "9f327f44-99ef-4ec7-83f2-a0420b681d2f"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Natural', 'Language'),\n",
              " ('Language', 'Processing'),\n",
              " ('Processing', '('),\n",
              " ('(', 'NLP'),\n",
              " ('NLP', ')'),\n",
              " (')', 'is'),\n",
              " ('is', 'a'),\n",
              " ('a', 'field'),\n",
              " ('field', 'of'),\n",
              " ('of', 'artificial'),\n",
              " ('artificial', 'intelligence'),\n",
              " ('intelligence', 'and'),\n",
              " ('and', 'computational'),\n",
              " ('computational', 'linguistics'),\n",
              " ('linguistics', 'that'),\n",
              " ('that', 'focuses'),\n",
              " ('focuses', 'on'),\n",
              " ('on', 'the'),\n",
              " ('the', 'interaction'),\n",
              " ('interaction', 'between'),\n",
              " ('between', 'computers'),\n",
              " ('computers', 'and'),\n",
              " ('and', 'human'),\n",
              " ('human', 'language'),\n",
              " ('language', '.'),\n",
              " ('.', 'It'),\n",
              " ('It', 'involves'),\n",
              " ('involves', 'developing'),\n",
              " ('developing', 'algorithms'),\n",
              " ('algorithms', 'and'),\n",
              " ('and', 'models'),\n",
              " ('models', 'to'),\n",
              " ('to', 'enable'),\n",
              " ('enable', 'computers'),\n",
              " ('computers', 'to'),\n",
              " ('to', 'understand'),\n",
              " ('understand', ','),\n",
              " (',', 'interpret'),\n",
              " ('interpret', ','),\n",
              " (',', 'and'),\n",
              " ('and', 'generate'),\n",
              " ('generate', 'natural'),\n",
              " ('natural', 'language'),\n",
              " ('language', '.'),\n",
              " ('.', 'The'),\n",
              " ('The', 'history'),\n",
              " ('history', 'of'),\n",
              " ('of', 'NLP'),\n",
              " ('NLP', 'dates'),\n",
              " ('dates', 'back'),\n",
              " ('back', 'to'),\n",
              " ('to', 'the'),\n",
              " ('the', '1950s'),\n",
              " ('1950s', 'when'),\n",
              " ('when', 'researchers'),\n",
              " ('researchers', 'started'),\n",
              " ('started', 'exploring'),\n",
              " ('exploring', 'machine'),\n",
              " ('machine', 'translation'),\n",
              " ('translation', 'and'),\n",
              " ('and', 'automatic'),\n",
              " ('automatic', 'language'),\n",
              " ('language', 'processing'),\n",
              " ('processing', '.'),\n",
              " ('.', 'The'),\n",
              " ('The', 'early'),\n",
              " ('early', 'years'),\n",
              " ('years', 'of'),\n",
              " ('of', 'NLP'),\n",
              " ('NLP', 'were'),\n",
              " ('were', 'primarily'),\n",
              " ('primarily', 'focused'),\n",
              " ('focused', 'on'),\n",
              " ('on', 'rule-based'),\n",
              " ('rule-based', 'systems'),\n",
              " ('systems', ','),\n",
              " (',', 'where'),\n",
              " ('where', 'linguistic'),\n",
              " ('linguistic', 'rules'),\n",
              " ('rules', 'and'),\n",
              " ('and', 'patterns'),\n",
              " ('patterns', 'were'),\n",
              " ('were', 'used'),\n",
              " ('used', 'to'),\n",
              " ('to', 'process'),\n",
              " ('process', 'and'),\n",
              " ('and', 'understand'),\n",
              " ('understand', 'text'),\n",
              " ('text', '.'),\n",
              " ('.', 'Today'),\n",
              " ('Today', ','),\n",
              " (',', 'NLP'),\n",
              " ('NLP', 'continues'),\n",
              " ('continues', 'to'),\n",
              " ('to', 'evolve'),\n",
              " ('evolve', 'rapidly'),\n",
              " ('rapidly', ','),\n",
              " (',', 'driven'),\n",
              " ('driven', 'by'),\n",
              " ('by', 'advancements'),\n",
              " ('advancements', 'in'),\n",
              " ('in', 'deep'),\n",
              " ('deep', 'learning'),\n",
              " ('learning', ','),\n",
              " (',', 'the'),\n",
              " ('the', 'availability'),\n",
              " ('availability', 'of'),\n",
              " ('of', 'vast'),\n",
              " ('vast', 'amounts'),\n",
              " ('amounts', 'of'),\n",
              " ('of', 'textual'),\n",
              " ('textual', 'data'),\n",
              " ('data', ','),\n",
              " (',', 'and'),\n",
              " ('and', 'the'),\n",
              " ('the', 'exploration'),\n",
              " ('exploration', 'of'),\n",
              " ('of', 'novel'),\n",
              " ('novel', 'techniques'),\n",
              " ('techniques', 'such'),\n",
              " ('such', 'as'),\n",
              " ('as', 'transfer'),\n",
              " ('transfer', 'learning'),\n",
              " ('learning', 'and'),\n",
              " ('and', 'reinforcement'),\n",
              " ('reinforcement', 'learning'),\n",
              " ('learning', '.'),\n",
              " ('.', 'The'),\n",
              " ('The', 'field'),\n",
              " ('field', 'is'),\n",
              " ('is', 'focused'),\n",
              " ('focused', 'on'),\n",
              " ('on', 'addressing'),\n",
              " ('addressing', 'challenges'),\n",
              " ('challenges', 'such'),\n",
              " ('such', 'as'),\n",
              " ('as', 'understanding'),\n",
              " ('understanding', 'context'),\n",
              " ('context', ','),\n",
              " (',', 'handling'),\n",
              " ('handling', 'ambiguity'),\n",
              " ('ambiguity', ','),\n",
              " (',', 'and'),\n",
              " ('and', 'enabling'),\n",
              " ('enabling', 'machines'),\n",
              " ('machines', 'to'),\n",
              " ('to', 'generate'),\n",
              " ('generate', 'human-like'),\n",
              " ('human-like', 'text'),\n",
              " ('text', ','),\n",
              " (',', 'opening'),\n",
              " ('opening', 'up'),\n",
              " ('up', 'exciting'),\n",
              " ('exciting', 'possibilities'),\n",
              " ('possibilities', 'for'),\n",
              " ('for', 'human-computer'),\n",
              " ('human-computer', 'interaction'),\n",
              " ('interaction', 'and'),\n",
              " ('and', 'language'),\n",
              " ('language', 'understanding'),\n",
              " ('understanding', '.')]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n = 5"
      ],
      "metadata": {
        "id": "cILQqOzYN9xI"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp_ngrams = list(nltk.ngrams(nlp_tokens, 5))\n",
        "nlp_ngrams"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kIdEqvUXNpdY",
        "outputId": "fdab8fdd-62f8-4912-c9d0-33e35e1cd6da"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Natural', 'Language', 'Processing', '(', 'NLP'),\n",
              " ('Language', 'Processing', '(', 'NLP', ')'),\n",
              " ('Processing', '(', 'NLP', ')', 'is'),\n",
              " ('(', 'NLP', ')', 'is', 'a'),\n",
              " ('NLP', ')', 'is', 'a', 'field'),\n",
              " (')', 'is', 'a', 'field', 'of'),\n",
              " ('is', 'a', 'field', 'of', 'artificial'),\n",
              " ('a', 'field', 'of', 'artificial', 'intelligence'),\n",
              " ('field', 'of', 'artificial', 'intelligence', 'and'),\n",
              " ('of', 'artificial', 'intelligence', 'and', 'computational'),\n",
              " ('artificial', 'intelligence', 'and', 'computational', 'linguistics'),\n",
              " ('intelligence', 'and', 'computational', 'linguistics', 'that'),\n",
              " ('and', 'computational', 'linguistics', 'that', 'focuses'),\n",
              " ('computational', 'linguistics', 'that', 'focuses', 'on'),\n",
              " ('linguistics', 'that', 'focuses', 'on', 'the'),\n",
              " ('that', 'focuses', 'on', 'the', 'interaction'),\n",
              " ('focuses', 'on', 'the', 'interaction', 'between'),\n",
              " ('on', 'the', 'interaction', 'between', 'computers'),\n",
              " ('the', 'interaction', 'between', 'computers', 'and'),\n",
              " ('interaction', 'between', 'computers', 'and', 'human'),\n",
              " ('between', 'computers', 'and', 'human', 'language'),\n",
              " ('computers', 'and', 'human', 'language', '.'),\n",
              " ('and', 'human', 'language', '.', 'It'),\n",
              " ('human', 'language', '.', 'It', 'involves'),\n",
              " ('language', '.', 'It', 'involves', 'developing'),\n",
              " ('.', 'It', 'involves', 'developing', 'algorithms'),\n",
              " ('It', 'involves', 'developing', 'algorithms', 'and'),\n",
              " ('involves', 'developing', 'algorithms', 'and', 'models'),\n",
              " ('developing', 'algorithms', 'and', 'models', 'to'),\n",
              " ('algorithms', 'and', 'models', 'to', 'enable'),\n",
              " ('and', 'models', 'to', 'enable', 'computers'),\n",
              " ('models', 'to', 'enable', 'computers', 'to'),\n",
              " ('to', 'enable', 'computers', 'to', 'understand'),\n",
              " ('enable', 'computers', 'to', 'understand', ','),\n",
              " ('computers', 'to', 'understand', ',', 'interpret'),\n",
              " ('to', 'understand', ',', 'interpret', ','),\n",
              " ('understand', ',', 'interpret', ',', 'and'),\n",
              " (',', 'interpret', ',', 'and', 'generate'),\n",
              " ('interpret', ',', 'and', 'generate', 'natural'),\n",
              " (',', 'and', 'generate', 'natural', 'language'),\n",
              " ('and', 'generate', 'natural', 'language', '.'),\n",
              " ('generate', 'natural', 'language', '.', 'The'),\n",
              " ('natural', 'language', '.', 'The', 'history'),\n",
              " ('language', '.', 'The', 'history', 'of'),\n",
              " ('.', 'The', 'history', 'of', 'NLP'),\n",
              " ('The', 'history', 'of', 'NLP', 'dates'),\n",
              " ('history', 'of', 'NLP', 'dates', 'back'),\n",
              " ('of', 'NLP', 'dates', 'back', 'to'),\n",
              " ('NLP', 'dates', 'back', 'to', 'the'),\n",
              " ('dates', 'back', 'to', 'the', '1950s'),\n",
              " ('back', 'to', 'the', '1950s', 'when'),\n",
              " ('to', 'the', '1950s', 'when', 'researchers'),\n",
              " ('the', '1950s', 'when', 'researchers', 'started'),\n",
              " ('1950s', 'when', 'researchers', 'started', 'exploring'),\n",
              " ('when', 'researchers', 'started', 'exploring', 'machine'),\n",
              " ('researchers', 'started', 'exploring', 'machine', 'translation'),\n",
              " ('started', 'exploring', 'machine', 'translation', 'and'),\n",
              " ('exploring', 'machine', 'translation', 'and', 'automatic'),\n",
              " ('machine', 'translation', 'and', 'automatic', 'language'),\n",
              " ('translation', 'and', 'automatic', 'language', 'processing'),\n",
              " ('and', 'automatic', 'language', 'processing', '.'),\n",
              " ('automatic', 'language', 'processing', '.', 'The'),\n",
              " ('language', 'processing', '.', 'The', 'early'),\n",
              " ('processing', '.', 'The', 'early', 'years'),\n",
              " ('.', 'The', 'early', 'years', 'of'),\n",
              " ('The', 'early', 'years', 'of', 'NLP'),\n",
              " ('early', 'years', 'of', 'NLP', 'were'),\n",
              " ('years', 'of', 'NLP', 'were', 'primarily'),\n",
              " ('of', 'NLP', 'were', 'primarily', 'focused'),\n",
              " ('NLP', 'were', 'primarily', 'focused', 'on'),\n",
              " ('were', 'primarily', 'focused', 'on', 'rule-based'),\n",
              " ('primarily', 'focused', 'on', 'rule-based', 'systems'),\n",
              " ('focused', 'on', 'rule-based', 'systems', ','),\n",
              " ('on', 'rule-based', 'systems', ',', 'where'),\n",
              " ('rule-based', 'systems', ',', 'where', 'linguistic'),\n",
              " ('systems', ',', 'where', 'linguistic', 'rules'),\n",
              " (',', 'where', 'linguistic', 'rules', 'and'),\n",
              " ('where', 'linguistic', 'rules', 'and', 'patterns'),\n",
              " ('linguistic', 'rules', 'and', 'patterns', 'were'),\n",
              " ('rules', 'and', 'patterns', 'were', 'used'),\n",
              " ('and', 'patterns', 'were', 'used', 'to'),\n",
              " ('patterns', 'were', 'used', 'to', 'process'),\n",
              " ('were', 'used', 'to', 'process', 'and'),\n",
              " ('used', 'to', 'process', 'and', 'understand'),\n",
              " ('to', 'process', 'and', 'understand', 'text'),\n",
              " ('process', 'and', 'understand', 'text', '.'),\n",
              " ('and', 'understand', 'text', '.', 'Today'),\n",
              " ('understand', 'text', '.', 'Today', ','),\n",
              " ('text', '.', 'Today', ',', 'NLP'),\n",
              " ('.', 'Today', ',', 'NLP', 'continues'),\n",
              " ('Today', ',', 'NLP', 'continues', 'to'),\n",
              " (',', 'NLP', 'continues', 'to', 'evolve'),\n",
              " ('NLP', 'continues', 'to', 'evolve', 'rapidly'),\n",
              " ('continues', 'to', 'evolve', 'rapidly', ','),\n",
              " ('to', 'evolve', 'rapidly', ',', 'driven'),\n",
              " ('evolve', 'rapidly', ',', 'driven', 'by'),\n",
              " ('rapidly', ',', 'driven', 'by', 'advancements'),\n",
              " (',', 'driven', 'by', 'advancements', 'in'),\n",
              " ('driven', 'by', 'advancements', 'in', 'deep'),\n",
              " ('by', 'advancements', 'in', 'deep', 'learning'),\n",
              " ('advancements', 'in', 'deep', 'learning', ','),\n",
              " ('in', 'deep', 'learning', ',', 'the'),\n",
              " ('deep', 'learning', ',', 'the', 'availability'),\n",
              " ('learning', ',', 'the', 'availability', 'of'),\n",
              " (',', 'the', 'availability', 'of', 'vast'),\n",
              " ('the', 'availability', 'of', 'vast', 'amounts'),\n",
              " ('availability', 'of', 'vast', 'amounts', 'of'),\n",
              " ('of', 'vast', 'amounts', 'of', 'textual'),\n",
              " ('vast', 'amounts', 'of', 'textual', 'data'),\n",
              " ('amounts', 'of', 'textual', 'data', ','),\n",
              " ('of', 'textual', 'data', ',', 'and'),\n",
              " ('textual', 'data', ',', 'and', 'the'),\n",
              " ('data', ',', 'and', 'the', 'exploration'),\n",
              " (',', 'and', 'the', 'exploration', 'of'),\n",
              " ('and', 'the', 'exploration', 'of', 'novel'),\n",
              " ('the', 'exploration', 'of', 'novel', 'techniques'),\n",
              " ('exploration', 'of', 'novel', 'techniques', 'such'),\n",
              " ('of', 'novel', 'techniques', 'such', 'as'),\n",
              " ('novel', 'techniques', 'such', 'as', 'transfer'),\n",
              " ('techniques', 'such', 'as', 'transfer', 'learning'),\n",
              " ('such', 'as', 'transfer', 'learning', 'and'),\n",
              " ('as', 'transfer', 'learning', 'and', 'reinforcement'),\n",
              " ('transfer', 'learning', 'and', 'reinforcement', 'learning'),\n",
              " ('learning', 'and', 'reinforcement', 'learning', '.'),\n",
              " ('and', 'reinforcement', 'learning', '.', 'The'),\n",
              " ('reinforcement', 'learning', '.', 'The', 'field'),\n",
              " ('learning', '.', 'The', 'field', 'is'),\n",
              " ('.', 'The', 'field', 'is', 'focused'),\n",
              " ('The', 'field', 'is', 'focused', 'on'),\n",
              " ('field', 'is', 'focused', 'on', 'addressing'),\n",
              " ('is', 'focused', 'on', 'addressing', 'challenges'),\n",
              " ('focused', 'on', 'addressing', 'challenges', 'such'),\n",
              " ('on', 'addressing', 'challenges', 'such', 'as'),\n",
              " ('addressing', 'challenges', 'such', 'as', 'understanding'),\n",
              " ('challenges', 'such', 'as', 'understanding', 'context'),\n",
              " ('such', 'as', 'understanding', 'context', ','),\n",
              " ('as', 'understanding', 'context', ',', 'handling'),\n",
              " ('understanding', 'context', ',', 'handling', 'ambiguity'),\n",
              " ('context', ',', 'handling', 'ambiguity', ','),\n",
              " (',', 'handling', 'ambiguity', ',', 'and'),\n",
              " ('handling', 'ambiguity', ',', 'and', 'enabling'),\n",
              " ('ambiguity', ',', 'and', 'enabling', 'machines'),\n",
              " (',', 'and', 'enabling', 'machines', 'to'),\n",
              " ('and', 'enabling', 'machines', 'to', 'generate'),\n",
              " ('enabling', 'machines', 'to', 'generate', 'human-like'),\n",
              " ('machines', 'to', 'generate', 'human-like', 'text'),\n",
              " ('to', 'generate', 'human-like', 'text', ','),\n",
              " ('generate', 'human-like', 'text', ',', 'opening'),\n",
              " ('human-like', 'text', ',', 'opening', 'up'),\n",
              " ('text', ',', 'opening', 'up', 'exciting'),\n",
              " (',', 'opening', 'up', 'exciting', 'possibilities'),\n",
              " ('opening', 'up', 'exciting', 'possibilities', 'for'),\n",
              " ('up', 'exciting', 'possibilities', 'for', 'human-computer'),\n",
              " ('exciting', 'possibilities', 'for', 'human-computer', 'interaction'),\n",
              " ('possibilities', 'for', 'human-computer', 'interaction', 'and'),\n",
              " ('for', 'human-computer', 'interaction', 'and', 'language'),\n",
              " ('human-computer', 'interaction', 'and', 'language', 'understanding'),\n",
              " ('interaction', 'and', 'language', 'understanding', '.')]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Cyswpcl0OAaN"
      },
      "execution_count": 25,
      "outputs": []
    }
  ]
}